---
template: Inbox
title: マイクロサービス負荷検証Geminiさんの見解
date: 2025-07-07
source: ソースを入れてください
tags:
  - 負荷検証
  - Shinise
  - 営業在庫
status: pending
priority: 高
aliases:
  - マイクロサービス
---

# 要約
- 

# 詳細メモ

## プロンプト
`````
# 役割
あなたは、GCPツールでの負荷検証の解析経験豊富なバックエンドエンジニアです。

# 現状
とある小売企業の基幹システム開発に携わっています。基幹システムはマイクロサービスアーキテクチャを採用しています。

現在、このマイクロサービスの一部に対する負荷検証を実施しており、
- Cloud Logging
- Cloud Monitoring
- Gatling
を使っています。GitHubリポジトリを作成し、全てKotlinで統合的に管理し、負荷検証解析データを出力するようにしています。ビルドツールはGradleです。

それぞれのサービス間で処理時間がわかるようにトレースIDを伝播させています。OpenTelemetryを使用しました。

対象マイクロサービスは2つで、サービス間はRabbitMQでメッセージングしています。具体的には
```
stock-conversion-service --> RabbitMQ --> new-stock-service
```
のようなフローです。
1. データの変換処理(stock-conversion-service)
2. レコードごとにメッセージを送信(stock-conversion-service)
3. データベースに情報を永続化(new-stock-service)
です。


#相談
トレースIDは伝播しているものの、1つのリクエストでレコードが１行ずつメッセージ＆後段処理が連鎖しているため、それぞれのサービス単位の処理時間を切り分けるのが難しいです。この場合、スパンID単位で処理時間を計測して、すべてのスパンIDに対して処理時間を集計し、統計量を算出したほうがいいですか？

懸念点として、テスト内容の中に、たくさんリクエストして負荷をかけるという項目があります。どの場合に、どの単位で集計したらいいのかわからなくなったので整理したく、質問しました。
`````

## Gemini応答
はい、ご認識の通り、**スパン単位で処理時間を計測し、すべてのスパンに対して統計量を算出するアプローチは、今回のようなアーキテクチャの負荷解析において非常に有効**です。

1つのリクエストが多数の非同期処理をトリガーするシステムでは、「リクエスト全体」と「個々の処理」の両方の視点で分析することがボトルネックを正確に特定する鍵となります。

---

### なぜスパン単位の分析が有効なのか？

`stock-conversion-service` への1リクエストが、後段の `new-stock-service` でN回のDB永続化処理を発生させる構成ですね。この場合、トレースIDは同じでも、実質的にはN個の独立した処理が並行（または直列）で動いている状態です。

- **トレース単位の分析だけでは不十分**: トレース全体の開始から終了までの時間だけを見てしまうと、個々のDB永続化処理のうち、**一部だけが極端に遅い「外れ値」を見逃してしまいます**。平均値に隠れてしまい、高負荷時に発生する特定の問題（例: 特定のデータに起因するロック競合、DBのコネクション待ちなど）の発見が遅れる可能性があります。    
- **スパン単位の分析で処理を分離**: OpenTelemetryのスパンは、まさしく個々の処理単位（DBアクセス、メッセージのpublish/consumeなど）を計測するためにあります。スパンごとに処理時間を集計することで、各サービス・各処理コンポーネントの性能を正確に評価できます。


---

### 推奨する分析単位と使い分け

負荷テストの目的や内容に応じて、以下の2つの単位を使い分けることをお勧めします。

| 分析単位       | 目的                  | 計測・集計対象                                                | わかること                                                                                                 |
| ---------- | ------------------- | ------------------------------------------------------ | ----------------------------------------------------------------------------------------------------- |
| **トレース単位** | **ユーザー視点での全体性能の把握** | Gatlingのリクエスト開始から、関連する最後のスパンが完了するまでの時間                 | ・システム全体のスループット  <br>・E2Eのレイテンシ  <br>・Gatlingの結果との相関                                                   |
| **スパン単位**  | **ボトルネックの特定**       | 特定の処理に対応するスパン名でグループ化し、各々の処理時間の統計量（平均、p95, p99, max）を算出 | ・`stock-conversion-service` の変換処理性能<br>・RabbitMQへのPublish/Consumeの性能<br>・`new-stock-service` のDB永続化性能 |

Google スプレッドシートにエクスポート

---

### 負荷シナリオ別の分析アプローチ

懸念されている「たくさんリクエストして負荷をかける」テストでは、以下のように分析を進めると効率的です。

#### 1. ベースラインの計測（低〜中負荷）
まずは、**スパン単位**の分析に注力します。
- **目的**: 各コンポーネントの基本的な処理性能（ベースライン）を把握する。
- **分析**:
    - `new-stock-service` の「DB永続化処理」スパンの処理時間（平均、p95）を確認する。
    - `stock-conversion-service` の「データ変換処理」スパンの処理時間を確認する。
    - RabbitMQのPublish/Consumeにかかる時間も同様に計測し、メッセージングのオーバーヘッドを把握する。

#### 2. 高負荷テスト（ストレステスト）
**スパン単位**と**トレース単位**の両方で分析します。
- **目的**: システムの限界性能（サチュレーションポイント）と、その原因となるボトルネックを特定する。
- **分析**:
    1. **スパン単位でボトルネックを探す**: 負荷を上げるにつれて、最初に処理時間のp99や最大値が著しく悪化するスパンを探します。例えば、「DB永続化処理」スパンの時間が急増した場合、DBの書き込み性能やコネクションプールがボトルネックである可能性が高いと判断できます。
    2. **トレース単位で全体への影響を確認する**: 特定のスパンの性能劣化が、システム全体の処理時間（トレース全体の時間）にどう影響するかを確認します。Gatlingのレポートでエラーレートが上昇したり、レスポンスタイムが悪化したりするタイミングと、Cloud Trace/Monitoring上で見つけたボトルネックの発生タイミングを突き合わせます。
    3. **キューの滞留を監視する**: Cloud MonitoringでRabbitMQのキューの深さ（`Ready Messages`）を監視します。`new-stock-service` の処理が追いつかなくなると、この値が増加し始めます。これは、ボトルネックを特定する上で非常に強力な指標です。

### まとめ
- **基本はスパン単位で分析**: 個々の処理性能を正確に評価し、ボトルネックを特定するために、**スパン名でグループ化して処理時間の統計量（特にp95, p99）を見る**のが基本戦略です。
    
- **全体像はトレース単位で補完**: ユーザー視点での全体的なパフォーマンスを確認するために、トレース全体の時間とGatlingの結果を併用します。
    
- **負荷レベルで見るべきポイントを変える**: 高負荷時は、平均値よりもp99や最大値、そしてRabbitMQのキューのようなリソース指標に注目することで、問題の兆候を早期に捉えることができます。
    

このアプローチにより、マイクロサービス間の複雑な連携の中でも、どの部分が性能の足かせになっているかをデータに基づいて明確に切り分けることができます。頑張ってください！

# 🔗 関連
