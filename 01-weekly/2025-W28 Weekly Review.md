
# 今週


◇詳細
営業在庫
- stock-conversion-service, new-stock-serviceの設定ファイルを修正し、Cloud Loggingでトレース情報を取得できるように調整
  
- Loggingの設定を環境変数でできるように調整
  
- デプロイして動作確認
  
- 予備調査
	- Lomosデータ１行レコードを、１秒間に１回ずつ、６０秒間にかけてサービスに負荷をかける。サービスレベルの処理時間を評価し、ここでは例として中央値をあげる。
	- stock-conversion-servieが 約100 msec、new-stock-serviceが約70 msec、それらを繋ぐRabbitMQが4 msecであるが、99%tile値が1000 msecと1桁程度大きい。キュー待ちが発生していると想定し、Cloud Monitoringを確認。
	- 現在、ポッドのスペックを低く設定しており、いきなり負荷がかかったことが原因。ポッドのスケーリング中で、その間の処理を止めていたと考えられる。時系列的にもスケーリング後には、レスポンスまでの時間が約100 msec以下であった。ポッドの設定をし直す必要がある。定量的にどれくらい上昇させるかは売上データによる負荷検証でベースラインを見る必要がある。
	  
- スパンレベルの処理時間のボトルネックを定量的に評価するために、Trace APIを調査。Gradle内でライブラリ依存関係の問題があり、難航中。
	- 追記：v1, 2あるうちのv1にしか読み取り機能がない。しかもこれからv2に以降していきそうな動き。
  
- libs.versions.tomlでライブラリの管理をするように修正。


◇その他
- 評価面談
- Kubernates hands on
- 1on1/宮崎さん --> キャンセル。諸事情のため。
- 1on1/村山さん

# 来週

◇営業在庫
- スパンレベルのボトルネック調査用のスクリプト作成
- 動作検証
- 売上データを使って負荷をかけれるようにGatlingを調整
- レポートとボトルネック原因調査

◇その他
- 月曜日のRetail AI
- 2次評価面談


# その他

## 星降る南阿蘇　2025
![[hukuokjashikagakukan.jpg]]


## 世界線