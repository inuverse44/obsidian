---
template: Inbox
title: 待ち行列理論によるGKEサイジング実践ガイド
date: 2025-07-08
source: ソースを入れてください
tags:
  - GKE
  - GCP
  - 待ち行列
status: pending
priority: 優先度
aliases:
---
# 待ち行列理論によるGKEサイジング実践ガイド：シナリオと検証計画

この記事では、GKEのPod数を決定するという現実的な課題に対し、待ち行列理論を用いて論理的な最適解を導き出し、さらにその結果を実際のGKE環境で検証するまでの一連のプロセスを解説します。

---

## 1. シナリオ：ビジネス要件から技術的課題へ

あるAPIサーバーを安定稼働させる、という典型的なシナリオを想定します。

-   **ビジネス要件**: ユーザー体験を損なわないよう、APIのレスポンスを高速に保ちたい。
-   **トラフィック予測**: ピークタイムには、平均して**1秒間に100リクエスト**が到着する ($\lambda = 100$ req/s)。
-   **SLO (サービスレベル目標)**: パフォーマンス目標として、「**APIの平均応答時間 (待ち時間＋処理時間) を100ms以内に収める**」と定義します。
    -   数学的には $W \le 0.1$秒 を目指します。

**解決すべき問い**: このSLOを達成するためには、最低何台のPod (`c`) を稼働させておく必要があるか？

---

## 2. 解決アプローチ：測定と予測の2ステップ

この問いに答えるため、現実の測定と数学的な予測を組み合わせます。

### Step 1: 【測定】単一Podのサービス率μの特定

まず、理論計算の根幹となる、Pod 1台あたりの性能限界を**負荷試験**によって実験的に測定します。

1.  **隔離**: Podを1台 (`replicas: 1`) のみ起動し、HPAを無効化します。
2.  **負荷**: 負荷テストツールを使い、このPodへのリクエストレートを段階的に（5, 10, 15, 20, 25... req/sと）増やしていきます。
3.  **観測**: 各負荷レベルで**応答時間**を監視します。
4.  **特定**: 応答時間が急激に悪化し始める直前のリクエストレートが、そのPodの**サービス率μ**となります。

**本シナリオでの仮定**: この試験の結果、サービス率は **μ = 20 req/s** （平均処理時間50ms）であったと仮定します。

### Step 2: 【予測】待ち行列理論による最適Pod数cの計算

次に、測定したμと目標到着率λを待ち行列モデルの公式に当てはめ、SLOを満たすPod数 `c` を計算します。

-   **パラメータ**:
    -   到着率 $\lambda = 100$
    -   サービス率 $\mu = 20$
-   **安定条件**: $\lambda < c \cdot \mu \implies 100 < c \cdot 20 \implies c > 5$。よって `c=6` から計算を開始します。

#### 計算結果

| Pod数 (`c`) | Pod利用率 ($\rho$) | 平均待ち時間 ($W_q$) | 平均応答時間 ($W = W_q + 50ms$) | SLO達成? (100ms以下) |
| :--- | :--- | :--- | :--- | :--- |
| **6** | 83.3% | 29.4 ms | **79.4 ms** | **✅ Yes** |
| **7** | 71.4% | 8.1 ms | **58.1 ms** | **✅ Yes** |
| **8** | 62.5% | 2.8 ms | **52.8 ms** | **✅ Yes** |

#### 結論
計算の結果、SLOを達成する最小Pod数は **`c=6`** であると論理的に導出されました。

---

## 3. GKEでの実践検証計画 🧪

最後に、この理論的な結論が現実世界でも正しいことを、GKE上で実験して証明します。

### 1. アプリケーション準備
-   **仕様**: HTTPリクエストに対し、意図的に `sleep(50ms)` を実行してからレスポンスを返す単純なWebアプリを用意します。これにより `μ=20` をシミュレートします。
-   **コンテナ化**: アプリをDockerイメージ化し、Artifact Registryにプッシュします。

### 2. 環境構築
-   **クラスタ**: **GKE Autopilot** モードでクラスタを作成し、コストを最小化します。
-   **リソース**: 上記コンテナイメージを使い、Deployment、Service (`ClusterIP`)、HPA (HorizontalPodAutoscaler) を作成します。

### 3. 負荷生成
-   **ツール**: `hey` や `k6` などの負荷テストツールを使用します。
-   **環境**: GKEクラスタと同じVPC内にGCEインスタンスを立て、そこから **秒間100リクエスト ($\lambda=100$)** の負荷を安定してServiceにかけ続けます。

### 4. 仮説検証
理論モデルの予測が正しいかを、以下の2つのケースで検証します。

#### 【ケース1】Pod数 `c=6` の再現
-   **HPA設定**: `targetCPUUtilizationPercentage: 80` （理論値83.3%に近いため）
-   **仮説**:
    1.  HPAによってPod数は **6台** で安定する。
    2.  負荷テストツールの計測結果で、平均応答時間が理論値である **~79.4ms** に近い値になる。

#### 【ケース2】Pod数 `c=7` の再現
-   **HPA設定**: `targetCPUUtilizationPercentage: 70` （理論値71.4%に近いため）
-   **仮説**:
    1.  HPAによってPod数は **7台** で安定する。
    2.  平均応答時間が理論値である **~58.1ms** 付近まで短縮される。