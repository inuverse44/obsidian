---
template: Inbox
title: Zenn 待ち行列理論で見るGKEのポッド数最適化
date: 2025-07-08
source: ソースを入れてください
tags:
  - GKE
  - CPA
  - 待ち行列
  - キュー
  - Zenn
  - Google
status: pending
priority: 最高
aliases:
---
#### マジで読み飛ばしていいところ
色々ありまして、Clood Professional Architectの勉強しています。アウトプットしようと思っても、「本や公式ページ、Udemiyで勉強したことを、ただただまとめるのはつまらんなあ」と駄々を捏ねて書いた記事１作目です。CPA関連で、この記事を含めて３報アップする予定です。

この記事を書くためにGeminiさんらと問答して、**待ち行列**なるものも新たに勉強することになりました（問答はしましたが、この記事を書いているのはすべて私です）。純粋な理論ばかり触ってきた私にって、応用数学は新鮮で、より現実の問題とリンクしてる感覚をひしひしと感じています。

もちろん学術書ではないので、ゴリゴリ数学の式変形をZennでやっても、あまり多くの人に反響がないと思います。S. Hawkingの著書である*A Brief History of Time*（ホーキング、宇宙を語る : ビッグバンからブラックホールまで）の冒頭には、数式を文書に入れると、その数だけ読者が1/2ずつ減少するという旨の話があります。流石に数式１つというわけにはいかないですが、紹介しながた進めていきます。詳細な式変形は備忘録として付録に記載します。

下記に関連する記事を添付する（予定）なので、ぜひフィードバックをいただけると嬉しいです。

## 概要
この記事では

# 導入

クラウドネィティブなマイクロサービスのデプロイ先としてGoogle Kubernates Engine (GKE)を想像する人は多いと思います。マイクロサービスとして動くそれぞれのサービスのポッド性能は、開発段階において人の感覚で決められることが多いのではないでしょうか？「とりあえず、他のサービスのCPUがこれくらいだから」「ベストプラクティスがこれくらいだから」という理由で決めてしまっていることが、GKE上で、いやそうでない一般の開発現場でも往々にして存在するのではないか、と予想しています（だって、人間だもの）。

ベストプラクティスという言葉は、効率的にで業務を回す日常において安心感のある言葉ではあります。一方でよくよく考えてみると、なぜベストプラクティスなのかは瞬時にわかりかねます（私に関しては経験不足によるものでしょうが）。「〇〇という状況を想像してみると、こちらのほうがよい」と、なんとなく説得させられた気になります。しかしながら、「ベストプラクティス」というただ単に過去の多くの経験から帰納的に考えられた都合のいい事象です。そのまま鵜呑みにすることは、なにか得体の知れないものを使い続けいているような気がして、ムズムズするという感覚が否めません。ベストプラクティスとして残っているならば、それに足る正当で厳格な自然があってもいいはずです。

そこで、帰納的な考えをできる限り排すことにし、数理モデルから演繹的に、ポッドの性能を決定をすることを目指します。

この記事ではGKEのポッドを待ち行列理論、および実務的な観点から、いくつかの仮定を置くことで、数理的に適切なポッド数を予想します。さらに、実際にGKEにて試験用ポッドをデプロイし、リクエスト負荷に対するポッドの性能検証を実施ことで、待ち行列理論と実測値の整合性を評価します。

この記事の構成は次のとおりです。

## 待ち行列理論 (queueing theory)とは
簡単にいうと、ある系の混雑状況を数学的に記述した理論のこと。物理的、社会的な洞察から要請する仮定を使い、得られた系の数学的な表現を、単に**モデル**ということが多いです。

混雑状況を数理的に表現するといことから、応用範囲は広く、レジに並ぶ顧客であったり、今回の記事にもなっているサーバなどの、性能評価に応用されることが多いようです。

ここで行列とは、線形代数でいう行列 (matrix)ではなく、並んでいる**列**(queue)を表します。

※英語版Wikipediaにも書いていますが、スペルが"queuing"と書かれる分野もあるそうですが、重要なジャーナルの一つは次のような雑誌名になっています：*Queueing Systems*

https://en.wikipedia.org/wiki/Queueing_theory

## Google Kubernates Engine (GKE)とは

コンテナのオーケストレーションツールです。GoogleのBorgらの論文から始まった、GoogleがGoogle Cloud Platfrom上で提供するサービスです。

コンテナに対して、管理、実行、オートスケール、オートヒーリング、ローリングアップデートなどなどを宣言的に処理することができる便利ツールですね。

https://queue.acm.org/detail.cfm?id=2898444

# 準備

## 数学的な仮定

今回採用する待ち行列のモデルとして、簡単なMMcモデルを採用します（理由は特にありません。時間が足らんかったんです泣）。ここで、MMcはそれぞれ
- M: マルコフ到着過程 (Markovian Arrival Process)　リクエストの到着がランダム
- M: マルコフサービス過程 (Markovian Service Process)　ポッドでの処理時間がランダム
- c: 処理を行うポッド数
であると仮定します。

### 到着過程
現実のリクエストはランダムに飛んでくると考えられます。もちろん、特定の時間に周期的に大量のリクエストが来るということはありますが、簡単のためにこの記事では言及いたしません。リクエストのランダムネスは、数学の言葉で**ポアソン分布**というものにモデル化することができます。単位時間の平均リクエスト数を$\lambda$とするとし、その単位時間で$k$回のリクエストが飛んでくると確率は
$$
	P(k) = 
	\frac{\lambda^k e^{-\lambda}}{k!}
$$
と与えられます。

（ポアソン分布と調べると、よく馬に蹴られて死んだ兵士の例が出てきますね）
![](https://storage.googleapis.com/zenn-user-upload/b13bb773ce1f-20250709.jpeg)

### サービス過程
GKEにデプロイされたアプリを担うポッドでの多くの処理は、これまでの処理の履歴に依存しないと考えられます。

例えばあるリクエストの処理に平均50 msecかかるとします。30 msecも経ったから、あともう直ぐで終わるというのは、平均という尺度を見ているから感じる感覚であって、実際は31 msecで終わることもあれば、100 msecかかることだってあります。確率は小さくとも1000 msecなんてことはあるやもしれません。このような事象の時間間隔にランダムネスがあるとき、数学の言葉では**指数分布**
$$
	p(t) 
	= \mu e^{-\mu t}
$$
という確率密度に変換することができます。ここで$\mu$は単位時間に処理できるリクエスト数です。単位時間を1 sec (= 1000 msec)とすれば、$\mu = 20$です。
![](https://storage.googleapis.com/zenn-user-upload/2aeb1be1fd8b-20250709.jpeg)

## モデル
リクエストをして、$c$個のポッドが処理するという系において、系内に$n$個のリクエストが残っている（ポッドで処理中&待ち行列にある）動的な確率は出生死滅仮定(birth-death process)として
$$
	\frac{\mathrm{d} P_n(t)}{\mathrm{d}t}
	= \lambda P_{n-1}(t)
	+ \mu_{n + 1} P_{n+1}(t)
	- (\lambda + \mu_n) P_n(t)
$$
と記述されます。これはPoisson分布や指数分布の性質（無記録性）を使うことと、状態間の遷移が隣同士の状態にしか依存しないことから導かれます。
https://ia601403.us.archive.org/13/items/in.ernet.dli.2015.134547/2015.134547.Queueing-Systems-Volume-1-Theory.pdf

これでポッドのスケールの過渡期を説明するとことができるかもしれませんが、かなり挑戦的な内容になります。オートスケールするタイミングなどを議論する場合には必要な要素で面白い内容だとは思いますが、今回のポッドの最適な数を理論的に見積もるということからは大きく逸脱してしまうので、この式そのままの解析はいたしません。

最適なポッドの数、つまり**あるべき状態を定義する**ということは、あるべき状態になったあと、その状態を維持するということです。状態を維持するということは、確率$P_n$が静的であることです。つまり、$\mathcal{d} P_n(t)/\mathcal{d} t = 0$が要請されます。そうすれば上記の微分方程式の右辺の$P_n$等も時間変化することはなくなるため、単なる差分方程式に落ち着きます。つまり、次のようなつり合いを表す式になります：
$$
	\underbrace{(\lambda + \mu_n) P_n(t)}_{\mbox{\tiny{状態$n$から$状態n-1$ or $n+1$への流れ}}}
	=
	\underbrace{\lambda P_{n-1}(t)}_{\mbox{\tiny{状態$n-1$から$n$への流れ}}}
	+ \underbrace{\mu_{n + 1} P_{n+1}(t)}_{\mbox{\tiny{状態$n+1$から$n$への流れ}}}
$$
実は、このような全体のつり合いの式が成り立つとき、より詳細な状態間のつり合いも成り立ちます（詳細つり合い）。つまり、
$$
	\lambda P_{n-1} 
	= \mu_n P_n
$$
です。イメージとしてはポッドにリクエストして、ある程度CPU使用が高い状態を維持しているとき、リクエストの早さと処理の速さが同じ、ということを表しています。

## GKE性能指標の導出
さて、上記の議論からGKEの性能指標を導出しましょう！ここまで３つの数式が登場しましたが、ここから使うのは最後の式、詳細釣り合いの式$\lambda P_{n-1} = \mu_n P_n$です。ステップとしては
1. $P_n$を求める
2. 確率の規格化条件から$P_0$を求める
3. $P_n$を使った指標を定義する
です。

### $P_n$を求める
詳細釣り合いの式から、$P_n$を$P_0$で表すことができます。ただし、リクエストが系に存在する数$n$とポッド数$c$の大小で場合分けが必要になります。
結果だけ書くと、
#### (i) $n < c$の場合
$$
	P_n 
	= \frac{1}{n!} \left( 
		\frac{\lambda}{\mu} 
	\right)^n P_0
	\tag{2}
$$
#### (ii) $n > c$の場合
$$
	P_n 
	= \frac{1}{c!} \left( 
		\frac{\lambda}{\mu} 
	\right)^c \left( 
		\frac{\lambda}{c\mu} 
	\right)^{n-c} P_0
	\tag{3}
$$
と表せます。

### $P_0$を求める
確率の規格化条件
$$
	\sum_{n = 0}^\infty
	P_n = 1
$$
を使います。上記の$(2), (3)$を代入することで、最終的に
$$
	P_0 
	= 
	\left[ 
		\sum_{n=0}^{c-1} \frac{1}{n!} \left( 
			\frac{\lambda}{\mu} 
		\right)^n + \frac{1}{c!} \left( 
			\frac{\lambda}{\mu} 
		\right)^c 
		\frac{c\mu}{c\mu - \lambda} 
	\right]^{-1}
	\tag{4}
$$
と表されます。無限和がでてきますが、高校数学ででてくる$\sum_{k = 1}^\infty r^k = 1/(1 - r)$を使えば導くことが出てきます。ここで暗に仮定しましたが、$\lambda < c\mu$です。もし$\lambda \geq c\mu$、つまり到着率が全ポッドの処理能力を上回るということは、どんどんリクエストが来ているにも関わらず、ポッドがそれを捌くことができていない状態であるということです。ですから、安定稼働しているという条件のために、$\lambda < c\mu$が要請されるのです。

### 評価指標を計算する

#### 平均待ち行列長
平均待ち行列長$L_q$を次のように定義します。
$$
	L_q 
	= \sum_{n=c}^\infty (n - c) P_n
	\tag{5}
$$
これはどう意味かというと、ポッドが全て埋まったときに、系で処理待ちしているリクエストの数です。状態$n$のとき、すなわち系にリクエストが$n$個存在する時、$c$個のポッドが$c$個のリクエストを処理中であり、$n - c$個が未処理（待ち行列）にあります。これを全ての場合について確率をかけて期待値を計算したものが上記の式になります。

ところで、$(3)$から$n > c$のときの$P_n$が与えられているため、具体的に$(5)$を計算することができます。結果だけ書くと

$$
	L_q
	=
	\underbrace{\frac{P_c}{1 - \rho}}_{\tiny{待ちが発生する確率}}
	\times 
	\underbrace{\frac{\rho}{1 - \rho}}_{\tiny{待ちのやばさ}}
$$

を得ることができます。ここで見やすさのために$\rho = \lambda/(c\mu)$としました。計算はちょっとだけ面倒ですが、等比数列の無限級数の導出を少し撚ればOKです。

ですが、ちょっとよくわかりません。なのでなるべく直感的な説明を考えてみます。

◇待ちが発生する確率

(a) $P_c$は系に$c$個のリクエストが存在する確率です。ちょうどポッドの数だけリクエストが存在し、はじめてポッドを占有するのがこのときです。なので、この状態で、さらにリクエストがくれば「待ち」が発生します。

(b) では、リクエストがすでに待っている状態$c+1, c+2, \ldots$の確率はなんでしょうか？$n \geq c$のとき、$(3)$から$P_n = P_c \rho^{n-c}$となっています。

これらを(a), (b)を総計することで、待ちが発生する確率$P_{\rm wait}$を計算できますね。よって

$$
	P_{\rm wait} 
	= \sum_{n = c} P_c \rho^{n - c} 
	= P_c \sum_{n = c} \rho^{n - c}
	= \frac{P_c}{1- \rho}
$$
となるのです。

◇待ちのやばさ
いい表現が思いつきませんでしたが、ポッドの処理が小さいとき、つまり$\rho = 0.01$のとき、近似的に$L_q \simeq 1.01 \times P_c$であり、待ちが長くなることはほとんどなく、すぐ解消されると言えます。

一方、$\rho = 0.99$のとき、$L_q = 10000 P_c$です。系の処理能力が限界に近いと、待っている処理が全然解消されないということです。ノートパソコンのCPUが限界近い時に、処理が死ぬほど重くなっているあの現象は、まさしくこれをが反映されているものだと勝手に思っています。

#### 平均待ち時間
待ちの長さがわかれば、処理の平均速度（=サービス率$\lambda$）を使うことで、平均待ち時間を知ることができます。小学校で学ぶ、距離と速さと時間の関係を使っているだけです：

$$
	W_q = \frac{L_q}{\lambda}
$$

#### パーセンタイル応答時間の計算
平均待ち時間が$W_q$なので、待ち時間が$t$以下である確率は
$$
	P(W_q \leq t)
	= 1 - e^{- t/W_q}
$$
です。詳細は省きますが、これは冒頭で紹介したポッドの処理時間が指数分布と仮定できる、ということに直接的に関わるものです。

待ち時間がこの時間以下になる確率が95%であることを求めましょう。これを95パーセンタイル待ち時間$W_{q, 95}$とします。すると、待ち時間が$W_{q, 95}$を越さない確率が$0.95$なので

$$
	0.95 = 1 - \exp
	\left[
		- \frac{W_{q, 95}}{W_q}
	\right]
$$
です。これを$W_{q, 95}$について解くと

$$
	W_{q, 95}
	= -W_q \underbrace{\log (0.05)}_{\simeq -2.995}
	\simeq 3 W_q
$$
です。そして、これは待ち時間なので、ユーザが体感する応答時間$W_{95}$は、上記に処理時間を足して、

$$
	W_{95}
	\simeq 3W_{q} + \frac{1}{\mu}
$$

となりますね。


### 具体的な計算例
さて、SLOを設定して、負荷検証を実施して、次が確定したとします：
- SLO: 95パーセンタイル時間が$200~{\rm msec}$以内に収める
- $\lambda$　リクエストが平均$\lambda = 100件 /{\rm sec}$
- $\mu$:　処理するにの$\mu = 20件/{\rm sec}$　

すると、ポッドの利用率$\rho$は

$$
	\rho = \frac{\lambda}{c\mu} 
	= \frac{100}{20c} 
	= \frac{5}{c}
$$

ここで、技術的要請から$c > 5$でなければなりません。ポッドの利用率が$100\%$は避けろ、と多くの人が言うでしょう。

ここまでできたら、$W_{95}$を計算できます。ただ、代数的に解くのは面倒なので、ここからはプログラムに任せましょう！$c = 6, 7, 8, \ldots$と増やすことで、要件を満たす$c$が自然とわかるはずです。

この結果によると、ポッドが6つの時点でレスポンスまでの時間が$138 ~ {\rm msec}$となります！















# 検証



# 結果

# まとめと展望

# 参考文献
- https://orsj.org/wp-content/or-archives50/pdf/bul/Vol.40_11_649.pdf
- https://www.scirp.org/journal/paperinformation?paperid=51426


# 付録
## Poisson分布の導出

## 指数分布の導出