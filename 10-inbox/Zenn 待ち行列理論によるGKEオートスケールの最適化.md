---
template: Inbox
title: 待ち行列理論によるGKEオートスケールの最適化
date: 2025-07-08
source: ソースを入れてください
tags:
  - GKE
  - CPA
  - 待ち行列
  - キュー
status: pending
priority: 最高
aliases:
---
#### マジで読み飛ばしていいところ
色々ありまして、Clood Professional Architectの勉強しています。アウトプットしようと思っても、「本や公式ページ、Udemiyで勉強したことを、ただただまとめるのはつまらんなあ」と駄々を捏ねて書いた記事１作目です。CPA関連で、この記事を含めて３報アップする予定です。

この記事を書くためにGeminiさんらと問答して、**待ち行列**なるものも新たに勉強することになりました。純粋な理論ばかり触ってきた私にって、応用数学は新鮮で、より現実の問題とリンクしてる感覚をひしひしと感じています。

ただ学術書ではないので、ゴリゴリ数学の式変形をZennでやっても、あまり多くの人に反響がないと思います。S. Hawkingの著書である*A Brief History of Time*（ホーキング、宇宙を語る : ビッグバンからブラックホールまで）の冒頭には、数式を文書に入れると、その数だけ読者が1/2ずつ減少するという旨の話があります。流石に数式１つというわけにはいかないですが、紹介しながた進めていきます。詳細な式変形は備忘録として付録に記載します。

下記に関連する記事を添付する（予定）なので、ぜひフィードバックをいただけると嬉しいです。

## 概要
この記事では

# 導入

クラウドネィティブなマイクロサービスのデプロイ先としてGoogle Kubernates Engine (GKE)を想像する人は多いと思います。マイクロサービスとして動くそれぞれのサービスのポッド性能は、開発段階において人の感覚で決められることが多いのではないでしょうか？「とりあえず、他のサービスのCPUがこれくらいだから」「ベストプラクティスがこれくらいだから」という理由で決めてしまっていることが、GKE上で、いやそうでない一般の開発現場でも往々にして存在するのではないか、と予想しています（だって、人間だもの）。

ベストプラクティスという言葉は、効率的にで業務を回す日常において安心感のある言葉ではあります。一方でよくよく考えてみると、なぜベストプラクティスなのかは瞬時にわかりかねます（私に関しては経験不足によるものでしょうが）。「〇〇という状況を想像してみると、こちらのほうがよい」と、なんとなく説得させられた気になります。しかしながら、「ベストプラクティス」というただ単に過去の多くの経験から帰納的に考えられた都合のいい事象です。そのまま鵜呑みにすることは、なにか得体の知れないものを使い続けいているような気がして、ムズムズするという感覚が否めません。ベストプラクティスとして残っているならば、それに足る正当で厳格な自然があってもいいはずです。

そこで、帰納的な考えをできる限り排すことにし、数理モデルから演繹的に、ポッドの性能を決定をすることを目指します。

この記事ではGKEのポッドを待ち行列理論、および実務的な観点から、いくつかの仮定を置くことで、数理的に適切なポッド数を予想します。さらに、実際にGKEにて試験用ポッドをデプロイし、リクエスト負荷に対するポッドの性能検証を実施ことで、待ち行列理論と実測値の整合性を評価します。

この記事の構成は次のとおりです。

## 待ち行列理論 (queueing theory)とは
簡単にいうと、ある系の混雑状況を数学的に記述した理論のこと。物理的、社会的な洞察から要請する仮定を使い、得られた系の数学的な表現を、単に**モデル**ということが多いです。

混雑状況を数理的に表現するといことから、応用範囲は広く、レジに並ぶ顧客であったり、今回の記事にもなっているサーバなどの、性能評価に応用されることが多いようです。

ここで行列とは、線形代数でいう行列 (matrix)ではなく、並んでいる**列**(queue)を表します。

※英語版Wikipediaにも書いていますが、スペルが"queuing"と書かれる分野もあるそうですが、重要なジャーナルの一つは次のような雑誌名になっています：*Queueing Systems*

https://en.wikipedia.org/wiki/Queueing_theory

## Google Kubernates Engine (GKE)とは

コンテナのオーケストレーションツールです。GoogleのBorgらの論文から始まった、GoogleがGoogle Cloud Platfrom上で提供するサービスです。

コンテナに対して、管理、実行、オートスケール、オートヒーリング、ローリングアップデートなどなどを宣言的に処理することができる便利ツールですね。

https://queue.acm.org/detail.cfm?id=2898444

# 準備

## 数学的な仮定

今回採用する待ち行列のモデルとして、簡単なMMcモデルを採用します（理由は特にありません。時間が足らんかったんです泣）。ここで、MMcはそれぞれ
- M: マルコフ到着過程 (Markovian Arrival Process)　リクエストの到着がランダム
- M: マルコフサービス過程 (Markovian Service Process)　ポッドでの処理時間がランダム
- c: 処理を行うポッド数
であると仮定します。

### 到着過程
現実のリクエストはランダムに飛んでくると考えられます。もちろん、特定の時間に周期的に大量のリクエストが来るということはありますが、簡単のためにこの記事では言及いたしません。リクエストのランダムネスは、数学の言葉で**ポアソン分布**というものにモデル化することができます。単位時間の平均リクエスト数を$\lambda$とするとし、その単位時間で$k$回のリクエストが飛んでくると確率は
$$
	P(k) = 
	\frac{\lambda^k e^\lambda}{k!}
$$
と与えられます。

ポアソン分布と調べると、よく馬に蹴られて死んだ兵士の例が出てきますね。

### サービス過程
GKEにデプロイされたアプリを担うポッドでの多くの処理は、これまでの処理の履歴に依存しないと考えられます。

例えばあるリクエストの処理に平均50 msecかかるとします。30 msecも経ったから、あともう直ぐで終わるというのは、平均という尺度を見ているから感じる感覚であって、実際は31 msecで終わることもあれば、100 msecかかることだってあります。確率は小さくとも1000 msecなんてことはあるやもしれません。このような事象の時間間隔にランダムネスがあるとき、数学の言葉では**指数分布**
$$
	p(t) 
	= \mu e^{-\mu t}
$$
という確率密度に変換することができます。ここで$\mu$は単位時間に処理できるリクエスト数です。単位時間を1 sec (= 1000 msec)とすれば、$\mu = 20$です。

# 検証

# 結果

# まとめと展望

# 参考文献
- https://orsj.org/wp-content/or-archives50/pdf/bul/Vol.40_11_649.pdf
- https://www.scirp.org/journal/paperinformation?paperid=51426


# 付録
## Poisson分布の導出

## 指数分布の導出